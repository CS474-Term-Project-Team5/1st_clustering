{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-20 17:36:45.433180\n",
      "0       The leader of the center-left People's Party g...\n",
      "1       PYEONGTAEK  -- South Korea has seized and insp...\n",
      "2       The crew of a Hong Kong-registered ship have b...\n",
      "3       South Korea has confirmed a fresh case of avia...\n",
      "4       A fine dust warning was issued in Seoul for a ...\n",
      "                              ...                        \n",
      "9121    North Korean leader Kim Jong-un is set to deli...\n",
      "9122    South Korea's Marine Corps will get new guided...\n",
      "9123    South Korea's defense chief stressed Sunday th...\n",
      "9124    North Korea kicked off the new year with a lar...\n",
      "9125    South Korea's acting President and Prime Minis...\n",
      "Name: description, Length: 9123, dtype: object\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e72e95476b28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from keybert import KeyBERT\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "# match left and right single quotes\n",
    "single_quote_expr = re.compile(r'[\\u2018\\u2019]', re.U)\n",
    "# match all non-basic latin unicode\n",
    "unicode_chars_expr = re.compile(r'[\\u0080-\\uffff]', re.U)\n",
    "ne_type = ['ORG','GPE','PERSON','NORP']\n",
    "\n",
    "def cleanse_unicode(s):\n",
    "    if not s:\n",
    "        return \"\"\n",
    "\n",
    "    temp = single_quote_expr.sub(\"'\", s, re.U)\n",
    "    temp = unicode_chars_expr.sub(\"\", temp, re.U)\n",
    "    return temp\n",
    "\n",
    "class data():\n",
    "    def __init__(self, pt):\n",
    "        self.path = pt\n",
    "        self.file_list = os.listdir(pt)\n",
    "\n",
    "\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "data_path = os.getcwd() + \"/data\"\n",
    "Data = data(data_path)\n",
    "kw_model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "for fp in Data.file_list:\n",
    "    with open(Data.path +\"/\" + fp, 'r') as f:\n",
    "        df=pd.read_csv(f)\n",
    "    \n",
    "    df = df[['title', 'author', 'time', 'description', 'body', 'section','month','year']].dropna()\n",
    "    print(df)\n",
    "    \n",
    "    keywords = []\n",
    "    nes = []\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        a = df.iloc[i]\n",
    "        temp_s = a['title'] + \". \" + a['description']\n",
    "        temp_s = temp_s.replace(\"[Newsmaker]\",\"\").replace(\"[Weekender]\",\"\").replace(\"(Yonhap)\",\"\")\n",
    "        # temp = []\n",
    "        # for j in range(1,6):\n",
    "        keyword = kw_model.extract_keywords(temp_s, keyphrase_ngram_range=(1,4), stop_words=None, use_mmr=True, diversity=0.1)\n",
    "        keyword = \" ,\".join([word[0] for word in keyword])\n",
    "        # print(keyword)\n",
    "        # temp = temp + keyword\n",
    "        keywords.append(keyword)\n",
    "\n",
    "        ne = [sp(a['description'])]\n",
    "        ne = [(e.text, e.lemma_, e.label_) for entities in ne for e in entities.ents]\n",
    "        ne = [n[1] for n in ne if n[2] in ne_type]\n",
    "        nes.append(ne)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            now = datetime.datetime.now()\n",
    "            print(now)\n",
    "            print(i)\n",
    "\n",
    "    df['keyword'] = keywords\n",
    "    df['ne'] = nes\n",
    "    print(df)\n",
    "    df.to_csv(fp +\"_ver_1.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def revise_word(a):\n",
    "    if \"www\" in a:\n",
    "        return None\n",
    "    return a.replace(\"'s\",\"\").rstrip()\n",
    "\n",
    "class BoW():\n",
    "    def __init__(self):\n",
    "        self.dic = {}\n",
    "        self.size = 0\n",
    "\n",
    "    def add_dic(self,words):\n",
    "        for word in words:\n",
    "            word = revise_word(word)\n",
    "            if word in self.dic or word is None:\n",
    "                pass\n",
    "            else:\n",
    "                self.dic[word] = self.size\n",
    "                self.size = self.size + 1\n",
    "\n",
    "    def make_vec(self,words):\n",
    "        shape = (self.size,)\n",
    "        zeros_tensors = torch.zeros(shape)\n",
    "        for word in words:\n",
    "            word = revise_word(word)\n",
    "            if word in self.dic:\n",
    "                zeros_tensors[self.dic[word]] += 1\n",
    "            elif word is None:\n",
    "                pass\n",
    "            else:\n",
    "                raise Exception(\"왜 딕셔너리에 없죠?\")\n",
    "        return zeros_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bow = BoW()\n",
    "\n",
    "data = pd.read_csv(\"./Data0_ver_1.csv\")\n",
    "\n",
    "dumps = data[:]['ne']\n",
    "dic = []\n",
    "for d in dumps:\n",
    "    d = ast.literal_eval(d)\n",
    "    bow.add_dic(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for i in range(data.shape[0]):\n",
    "    a = data.iloc[i]\n",
    "\n",
    "    ne = ast.literal_eval(a[\"ne\"])\n",
    "    ne_outputs = bow.make_vec(ne)\n",
    "\n",
    "\n",
    "    key = a[\"keyword\"]\n",
    "    inputs = tokenizer(key, return_tensors='pt')\n",
    "    key_outputs = model(**inputs).last_hidden_state[0][0]\n",
    "    vector = torch.cat((ne_outputs,key_outputs),0)\n",
    "    vectors.append(vector)\n",
    "\n",
    "data['vector'] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                                              title  \\\n",
      "0              0      A snapshot of multiculturalism in South Korea   \n",
      "1              1                   [Weekender] Korea’s dynamic 2017   \n",
      "2              2  People's Party members support Ahn's push for ...   \n",
      "3              3  [Newsmaker] Panamanian vessel probed over susp...   \n",
      "4              4  Hong Kong ship crew questioned in S. Korea for...   \n",
      "...          ...                                                ...   \n",
      "2995        2995                 Eyes on validity of Samsung merger   \n",
      "2996        2996  Number of visitors to overpass-turned-park top...   \n",
      "2997        2997  N. Korean propaganda leaflets on ‘missile succ...   \n",
      "2998        2998  Row over smoking indoors ends in attempted murder   \n",
      "2999        2999  [Newsmaker] Ahn elected new People's Party leader   \n",
      "\n",
      "             author                 time  \\\n",
      "0     Lee Sun-young  2018-01-01 17:07:00   \n",
      "1       Choi He-suk  2018-01-01 13:22:00   \n",
      "2            Yonhap  2017-12-31 16:18:00   \n",
      "3            Yonhap  2017-12-31 14:55:00   \n",
      "4               AFP  2017-12-30 15:44:00   \n",
      "...             ...                  ...   \n",
      "2995    Bak Se-hwan  2017-08-27 16:38:00   \n",
      "2996         Yonhap  2017-08-27 16:14:00   \n",
      "2997    Kim Min-joo  2017-08-27 16:01:00   \n",
      "2998    Kim Min-joo  2017-08-27 15:58:00   \n",
      "2999         Yonhap  2017-08-27 15:47:00   \n",
      "\n",
      "                                            description  \\\n",
      "0     With birthrates persistently low and the senio...   \n",
      "1     From North Korea’s nuclear weapons program nea...   \n",
      "2     The leader of the center-left People's Party g...   \n",
      "3     PYEONGTAEK  -- South Korea has seized and insp...   \n",
      "4     The crew of a Hong Kong-registered ship have b...   \n",
      "...                                                 ...   \n",
      "2995  Following the conviction of Samsung Group heir...   \n",
      "2996  The number of visitors to the overpass-turned-...   \n",
      "2997  Propaganda leaflets, presumably distributed by...   \n",
      "2998  A 51-year-old man has been sentenced to three ...   \n",
      "2999  Ahn Cheol-soo, the former presidential candida...   \n",
      "\n",
      "                                                   body         section  \\\n",
      "0     With birthrates persistently low and the senio...  Social affairs   \n",
      "1     From North Korea’s nuclear weapons program nea...  Social affairs   \n",
      "2     The leader of the center-left People's Party g...        Politics   \n",
      "3     PYEONGTAEK  -- South Korea has seized and insp...     North Korea   \n",
      "4     The crew of a Hong Kong-registered ship have b...     North Korea   \n",
      "...                                                 ...             ...   \n",
      "2995  Following the conviction of Samsung Group heir...  Social affairs   \n",
      "2996  The number of visitors to the overpass-turned-...  Social affairs   \n",
      "2997  Propaganda leaflets, presumably distributed by...     North Korea   \n",
      "2998  A 51-year-old man has been sentenced to three ...  Social affairs   \n",
      "2999  Ahn Cheol-soo, the former presidential candida...        Politics   \n",
      "\n",
      "                                                keyword  \\\n",
      "0     population growing south korea ,south korea wi...   \n",
      "1     unprecedented impeachment of president ,first ...   \n",
      "2     country third largest party ,the party announc...   \n",
      "3     oil supplies to korea ,panama flagged ship sus...   \n",
      "4     crew questioned in korea ,their tanker was imp...   \n",
      "...                                                 ...   \n",
      "2995  validity of samsung merger ,jae yong for bribe...   \n",
      "2996  park tops million since ,seoullo 7017 surpasse...   \n",
      "2997  seoul over the weekend ,weekend police said su...   \n",
      "2998  murder after assaulting pub ,prison for attemp...   \n",
      "2999  leadership election the entrepreneur ,turned p...   \n",
      "\n",
      "                                                     ne  \\\n",
      "0                     ['South Korea‘s', 'south korean']   \n",
      "1        ['North Korea ’s', 'South Korea', 'Park Geun']   \n",
      "2      [\"People 's Party\", 'Ahn Cheol', 'Bareun Party']   \n",
      "3     ['PYEONGTAEK', 'South Korea', 'Panama', 'North...   \n",
      "4     ['Hong Kong', 'South Korea', 'north korean', '...   \n",
      "...                                                 ...   \n",
      "2995  ['Samsung Group', 'Lee Jae - yong', 'Samsung',...   \n",
      "2996  ['Seoullo', 'Seoul', 'the Seoul Metropolitan G...   \n",
      "2997  ['propaganda', 'North Korea', 'Seoul', 'Seoul'...   \n",
      "2998                      ['Daegu High Court', 'Daegu']   \n",
      "2999  ['Ahn Cheol', \"People 's Party\", 'Chung Dong -...   \n",
      "\n",
      "                                                 vector  \n",
      "0     [tensor(1., grad_fn=<UnbindBackward>), tensor(...  \n",
      "1     [tensor(0., grad_fn=<UnbindBackward>), tensor(...  \n",
      "2     [tensor(0., grad_fn=<UnbindBackward>), tensor(...  \n",
      "3     [tensor(0., grad_fn=<UnbindBackward>), tensor(...  \n",
      "4     [tensor(0., grad_fn=<UnbindBackward>), tensor(...  \n",
      "...                                                 ...  \n",
      "2995  [tensor(0., grad_fn=<UnbindBackward>), tensor(...  \n",
      "2996  [tensor(0., grad_fn=<UnbindBackward>), tensor(...  \n",
      "2997  [tensor(0., grad_fn=<UnbindBackward>), tensor(...  \n",
      "2998  [tensor(0., grad_fn=<UnbindBackward>), tensor(...  \n",
      "2999  [tensor(0., grad_fn=<UnbindBackward>), tensor(...  \n",
      "\n",
      "[3000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=3608.985596, iteration=1, tol=0.000100]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda:1..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[running kmeans]: 28it [00:02, 10.44it/s, center_shift=0.000000, iteration=29, tol=0.000100]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from kmeans_pytorch import kmeans\n",
    "\n",
    "cluster_ids_x, cluster_centers = kmeans(X=torch.stack(vectors),num_clusters = 10, distance='euclidean',device=torch.device('cuda:1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster_ids_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1c24ee1aed92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_ids_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cluster_ids_x' is not defined"
     ]
    }
   ],
   "source": [
    "data['cluster'] = cluster_ids_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                                              title  \\\n",
      "0              0      A snapshot of multiculturalism in South Korea   \n",
      "1              1                   [Weekender] Korea’s dynamic 2017   \n",
      "2              2  People's Party members support Ahn's push for ...   \n",
      "3              3  [Newsmaker] Panamanian vessel probed over susp...   \n",
      "4              4  Hong Kong ship crew questioned in S. Korea for...   \n",
      "...          ...                                                ...   \n",
      "2995        2995                 Eyes on validity of Samsung merger   \n",
      "2996        2996  Number of visitors to overpass-turned-park top...   \n",
      "2997        2997  N. Korean propaganda leaflets on ‘missile succ...   \n",
      "2998        2998  Row over smoking indoors ends in attempted murder   \n",
      "2999        2999  [Newsmaker] Ahn elected new People's Party leader   \n",
      "\n",
      "             author                 time  \\\n",
      "0     Lee Sun-young  2018-01-01 17:07:00   \n",
      "1       Choi He-suk  2018-01-01 13:22:00   \n",
      "2            Yonhap  2017-12-31 16:18:00   \n",
      "3            Yonhap  2017-12-31 14:55:00   \n",
      "4               AFP  2017-12-30 15:44:00   \n",
      "...             ...                  ...   \n",
      "2995    Bak Se-hwan  2017-08-27 16:38:00   \n",
      "2996         Yonhap  2017-08-27 16:14:00   \n",
      "2997    Kim Min-joo  2017-08-27 16:01:00   \n",
      "2998    Kim Min-joo  2017-08-27 15:58:00   \n",
      "2999         Yonhap  2017-08-27 15:47:00   \n",
      "\n",
      "                                            description  \\\n",
      "0     With birthrates persistently low and the senio...   \n",
      "1     From North Korea’s nuclear weapons program nea...   \n",
      "2     The leader of the center-left People's Party g...   \n",
      "3     PYEONGTAEK  -- South Korea has seized and insp...   \n",
      "4     The crew of a Hong Kong-registered ship have b...   \n",
      "...                                                 ...   \n",
      "2995  Following the conviction of Samsung Group heir...   \n",
      "2996  The number of visitors to the overpass-turned-...   \n",
      "2997  Propaganda leaflets, presumably distributed by...   \n",
      "2998  A 51-year-old man has been sentenced to three ...   \n",
      "2999  Ahn Cheol-soo, the former presidential candida...   \n",
      "\n",
      "                                                   body         section  \\\n",
      "0     With birthrates persistently low and the senio...  Social affairs   \n",
      "1     From North Korea’s nuclear weapons program nea...  Social affairs   \n",
      "2     The leader of the center-left People's Party g...        Politics   \n",
      "3     PYEONGTAEK  -- South Korea has seized and insp...     North Korea   \n",
      "4     The crew of a Hong Kong-registered ship have b...     North Korea   \n",
      "...                                                 ...             ...   \n",
      "2995  Following the conviction of Samsung Group heir...  Social affairs   \n",
      "2996  The number of visitors to the overpass-turned-...  Social affairs   \n",
      "2997  Propaganda leaflets, presumably distributed by...     North Korea   \n",
      "2998  A 51-year-old man has been sentenced to three ...  Social affairs   \n",
      "2999  Ahn Cheol-soo, the former presidential candida...        Politics   \n",
      "\n",
      "                                                keyword  \\\n",
      "0     population growing south korea ,south korea wi...   \n",
      "1     unprecedented impeachment of president ,first ...   \n",
      "2     country third largest party ,the party announc...   \n",
      "3     oil supplies to korea ,panama flagged ship sus...   \n",
      "4     crew questioned in korea ,their tanker was imp...   \n",
      "...                                                 ...   \n",
      "2995  validity of samsung merger ,jae yong for bribe...   \n",
      "2996  park tops million since ,seoullo 7017 surpasse...   \n",
      "2997  seoul over the weekend ,weekend police said su...   \n",
      "2998  murder after assaulting pub ,prison for attemp...   \n",
      "2999  leadership election the entrepreneur ,turned p...   \n",
      "\n",
      "                                                     ne  \\\n",
      "0                     ['South Korea‘s', 'south korean']   \n",
      "1        ['North Korea ’s', 'South Korea', 'Park Geun']   \n",
      "2      [\"People 's Party\", 'Ahn Cheol', 'Bareun Party']   \n",
      "3     ['PYEONGTAEK', 'South Korea', 'Panama', 'North...   \n",
      "4     ['Hong Kong', 'South Korea', 'north korean', '...   \n",
      "...                                                 ...   \n",
      "2995  ['Samsung Group', 'Lee Jae - yong', 'Samsung',...   \n",
      "2996  ['Seoullo', 'Seoul', 'the Seoul Metropolitan G...   \n",
      "2997  ['propaganda', 'North Korea', 'Seoul', 'Seoul'...   \n",
      "2998                      ['Daegu High Court', 'Daegu']   \n",
      "2999  ['Ahn Cheol', \"People 's Party\", 'Chung Dong -...   \n",
      "\n",
      "                                                 vector  cluster  \n",
      "0     [tensor(1., grad_fn=<UnbindBackward>), tensor(...        0  \n",
      "1     [tensor(0., grad_fn=<UnbindBackward>), tensor(...        5  \n",
      "2     [tensor(0., grad_fn=<UnbindBackward>), tensor(...        5  \n",
      "3     [tensor(0., grad_fn=<UnbindBackward>), tensor(...        3  \n",
      "4     [tensor(0., grad_fn=<UnbindBackward>), tensor(...        2  \n",
      "...                                                 ...      ...  \n",
      "2995  [tensor(0., grad_fn=<UnbindBackward>), tensor(...        5  \n",
      "2996  [tensor(0., grad_fn=<UnbindBackward>), tensor(...        0  \n",
      "2997  [tensor(0., grad_fn=<UnbindBackward>), tensor(...        7  \n",
      "2998  [tensor(0., grad_fn=<UnbindBackward>), tensor(...        1  \n",
      "2999  [tensor(0., grad_fn=<UnbindBackward>), tensor(...        5  \n",
      "\n",
      "[3000 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'data' has no attribute 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-92ef8519af45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf_des\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'data' has no attribute 'loc'"
     ]
    }
   ],
   "source": [
    "\n",
    "for k in range(10):\n",
    "    df_0 = data.loc[data['cluster'] == k]\n",
    "\n",
    "    df_des = list(df_0[' description'][:])\n",
    "\n",
    "    vocab = {}\n",
    "\n",
    "    n = 3\n",
    "\n",
    "    for doc in df_des:\n",
    "        if type(doc) == type('str'):\n",
    "            a = [w.replace(\".\",\"\").replace(\",\",\"\").replace(\"!\",\"\").replace(\"?\",\"\").replace(\"'\",\"\").replace('\"',\"\").replace(\"\\n\",\"\") for w in doc.split()]\n",
    "            for i in range(len(a)-n+1):\n",
    "                if n != 1:\n",
    "                    word = \" \".join(a[i:i+n])\n",
    "                if word in vocab:\n",
    "                    vocab[word] += 1\n",
    "                else:\n",
    "                    vocab[word] = 1\n",
    "\n",
    "                    \n",
    "    vocab = vocab.items()\n",
    "\n",
    "    vocab = sorted(vocab,key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    print(vocab[0:5])\n",
    "    \n",
    "    n = 5\n",
    "    vocab = {}\n",
    "    for doc in df_des:\n",
    "        if type(doc) == type('str'):\n",
    "            a = [w.replace(\".\",\"\").replace(\",\",\"\").replace(\"!\",\"\").replace(\"?\",\"\").replace(\"'\",\"\").replace('\"',\"\").replace(\"\\n\",\"\") for w in doc.split()]\n",
    "            for i in range(len(a)-n+1):\n",
    "                if n != 1:\n",
    "                    word = \" \".join(a[i:i+n])\n",
    "                if word in vocab:\n",
    "                    vocab[word] += 1\n",
    "                else:\n",
    "                    vocab[word] = 1\n",
    "                    \n",
    "    vocab = vocab.items()\n",
    "\n",
    "    vocab = sorted(vocab,key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    print(vocab[0:5])\n",
    "    print(\"------------------------------\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
